

**Where**
```
SELECT * 
FROM table 
WHERE condition1 
	AND/OR condition2 
	AND/OR condition3;
```
- think of it like excel filter

**Conditional**
- And
- Or
- Not

**Between**
- Where + Between
	- Selects values within a given range
	- has to be pared with 'AND'
		- where column_name between value1 and value2;
- Inclusive
	- both start and end

**IN**
- allows us to specify multiple values in a single line's WHERE clause instead of having to use multiple OR conditions to filter multiple values
- where column in (....);
	- checks if particular column value matches anything in the value you specify

**LIKE**
- filter rows based on whether a string matches a certain pattern
- where column like ....
- and/or column not like ...

	**%**
	- wild-card
	- `where drug like "%Relief%"`
	- zero or more characters

	**`_`**
	- wildcard to represent a **single** character
	- 4 letter words taht begin with 'f' and have 'c' as 3rd letter
		- `where word like "f_c_"`

**RLIKE / regexp**
- regex
- `'^[a-z0-9._%+-]+@[a-z0-9.-]+\\.com$';`

**regexp_like()**
- boolean test

**regexp_replace()**
- replace
- can use this to count the frequency of the pattern

**regexp_substr()**
- return first substring matching regex

**regexp_instr()**
- return position of match

**basic logic operation**
- =
- !=, <>
- <, >
- <=, >=
- Between ... and ...

**ORDER BY**
- asc by default
- order by column asc/desc;
- order by column1 asc, column2 desc; # multiple col
```
select policy_holder_id, call_category, call_received
from callers
order by 1,3 desc;
```
- 1 : policy_holder_id
- 3 : call_received

**LIMIT**
- `order by call_received desc`
- `limit 5;`
- top 5 most rescent phone calls í•œì •

**OFFSET**
- control results returned
- `offset 10`
	- skip first 10 rows


**Aggregate Functions**
1. SUM
2. MIN
3. MAX
4. AVG
5. COUNT

*Example*
- calculating total sales
	- select sum(*)
- Average rating for product reviews
	- select avg()
- identify most active users
	- select count(posts), group_by user_id
- lowest and highest prices
	- select max(prices), min(prices)

**GROUP BY w agg**
- select target to aggregate
- multiple categories
	- group by ticker, year
- again, we can identify the column name via number
	- group by 1, 2

**GROUP BY w HAVING**
- *agg function is not allowed in WHERE*
	- `where avg(open) > 200` is not allowed
- allows you to filter data based on values from aggregated functions
	- kinda like lambda

**WHERE vs HAVING**
- Where
	- filters on values in individual rows
- Having
	- filters values aggregated from groups of rows

**Having without Group by**
- it is technically possible to have HAVING without GROUP BY
- it works the same as where

**Distinct**
- helpful for data exploration
- may include two or more columns (return unique pairs)
- may use distinct with **agg functions**
	- count(distinct user_id) # most often used
	- distinct goes inside the agg function

**Arithmetic**
- math expressions to transform column values
- - 
- +
- *
- /
- %
- ^
- parentheses -> exponents -> multiplications & division -> add/subtract

**Math Functions**
- ABS
	- Absolute number
- Round
	- Round(number, 2)
	- 2 : number of decimal present
- **CEIL**
	- round up
- **FLOOR**
	- round down
- **Power**
	- `power(number, 2)`
	- `^2`
- **MOD**
	- %5 == 0
	- mod(number, 5)

**division**
- '/' treats integers (whole numbers) differently than in excel
- integer division discards the remainder from the output

*including decimal points*
1. use cast
	- cast(10 as decimal)
2. multiply by 1.0
	- `10 * 1.0 / 6`
3. explicit type specification using **`::`**
	- 10::DECIMAL/4    # 2.500000000
	- 10::FLOAT/4         # 2.5
	- 10/4::DECIMAL    # 2.50000000
	- 10/4::FLOAT         # 2.5
 
**CAST**
- converts one or both operands into decimal or floating-point data types
- cast(number AS DECIMAL)
- cast(number AS FLOAT)

**percentage**
- `(a / b) * 100`

**nulls**
- cannot use `=` comparison with null
- null is considered the smallest value hence when you sort it, it ascends to top of the list
- **IS NULL**
	- used to identify null and non-null values
	- is not null
- **COALESCE()**
	- takes multiple inputs and return first non-null value
	- coalesce(col_name, 'expression') or coalesce(col1, col2, col3, 'expression')
		- if expression is specified, it returns the expression
		- else it returns the value of column_name
		- check from the front col1, col2, col3, until its not null, else return expression
- **IFNULL()**
	- ifnull(column_name, value_if_null)
- **coalesce vs ifnull**
	- coalesce : versatile for multiple arguments
	- ifnull : handles two arguments

**Case + Select**
- used to create new columns, categorize data, perform calculations
```sql
SELECT 
	column_1, 
	column_2, 
	CASE 
		WHEN condition_1 THEN result_1 
		WHEN condition_2 THEN result_2 
		WHEN ... THEN ... 
		ELSE result_3
	END AS column_3_name
```

**Case + Where**
- filter rows based on specified conditions
- same column, different conditions for different values

```sql
SELECT 
column_1, 
column_2 
FROM table_1 
WHERE CASE 
WHEN platform = "instagram" THEN followers >= 500000 
WHEN condition_2 THEN result_2 
WHEN ... THEN ... 
ELSE result_3
end;
```

**count + case**
```sql
select
	platform
	count(case
		when followers >= 500000 then 1
		else null
		end) as popular_actor_count,
	count(case
		when followers < 500000 then 1
		else null) as less_popular_actor_count
from marvel_avengers
group by platform;
```

**sum + case**
```sql
SELECT 
	platform, 
	SUM(CASE 
		WHEN engagement_rate >= 8.0 
		THEN followers ELSE 0 END) 
	AS high_engagement_followers_sum,
```

**joins**
1. **INNER JOIN**
	- returns only the rows with matching values from both tables
2. **LEFT JOIN**
	- all rows from left table is fetched, and matching rows from right tables
3. **RIGHT JOIN**
	- all rows from right table is fetched, and matching rows from left table
4. **FULL OUTER JOIN**
	- returns all rows

**Conditional Joins**
```
select g.book_title, ,o.quantity
from goodreads as g
inner join orders as o
on g.book_id = o.book_id
	and o.quantity > 2;
```
- applies condition as part of join
	1. if the condition `o.quantity > 2` affects the joining key
		- filter the output
	2. if the condition does not affect the joining key
		- all values of that column that does not meet the condition, you can think of it as null values

**self joins**
- find similar books within the same genre

```
select 
	b1.genre,
	b1.book_title as current_book
	b2.book_title as suggested_book
from 
	goodreads as b1 inner join goodreads as b2
on 
	b1.genre = b2.genre
where
	b1.genre = b2.genre
order by
	b1.book_title
```
- creates a cartesian join within genre

**UNION**
- combine data vertically
- **rules**
	- number of columns in each select must match
	- data types of columns must match
	- columns selected must be in the same order
- **gives list of unique values without duplicates**

**UNION ALL**
- combines results from two or more select statements
- **it includes all values including duplicates**

```
select ingredient
from recipe1 union all
select ingredient
from recepie2;
```

**INTERSECT**
- finding intersect
```
select first_name, last_name
from employees
intersect
select first_name, last_name
from customers;
```
- remove duplicates

**INTERSECT ALL**
- finding intersect
```
select first_name, last_name
from employees
intersect all
select first_name, last_name
from customers;
```
- preserves duplicates









**`CURRENT_DATE`**
- returns today's date

**`CURRENT_TIME`**
- returns the current time without the date

**`CURRENT_TIMESTAMP or NOW()`**
- returns the current date and time

*can use >, =, < operands to timestamp/date*

**Extract**
- extracts a specific component from a date or timestamp

**Date_part()**
- extracts a specific component from a date or timestamp

```sql
EXTRACT(YEAR FROM sent_date) AS extracted_year, DATE_PART('year', sent_date) AS part_year, EXTRACT(MONTH FROM sent_date) AS extracted_month, DATE_PART('month', sent_date) AS part_month, EXTRACT(DAY FROM sent_date) AS extracted_day, DATE_PART('day', sent_date) AS part_day, EXTRACT(HOUR FROM sent_date) AS extracted_hour, DATE_PART('hour', sent_date) AS part_hour, EXTRACT(MINUTE FROM sent_date) AS extracted_minute, DATE_PART('minute', sent_date) AS part_minute
```

**date_trunc**
- `date_trunc('month', sent_date)`

08/03/2022 16:43:00
- **trunc to month**
	- `08/01/2022 00:00:00`
- **trunc to day**
	- `08/03/2022 00:00:00`
- **trunc to hour**
	- `08/03/2022 16:00:00`
- behaves like **floor** not round

**Interval**
- used for adding/subtracting date and time gaps
- `+ interval '2 days'`
- `- interval 2 hours`

**to_char**
- convert date or timestamp to a string (specified format)
- `to_char(sent_date, 'YYYY-MM-DD HH:MI:SS')`

**to_date**
- convert string to date or timestamp
- `to_date('2023-08-27, 'YYYY-MM-DD')`


*Date ê´€ë ¨í•´ì„œ mysql vs postgresql*
https://datalemur.com/blog/mysql-postgresql-date-time-functions

---
https://datalemur.com/sql-tutorial/sql-cte-subquery

**CTE (Common Table Expression)**
- query within query
- creating temporary table using `WITH`

**Subqueries**
- embed one query within another
- nesting them via parentheses

**When to use CTE or Subquery**
- **CTE**
	- break down complex queries
```
with genre_revenue_cte as (
	select genre, sum(concert_revenue) as total_revenue
	from concerts
	groupby genre
)

select g.genre, g.total_revenue,
```
- when you need to reuse the subquery results, cte is useful
- when you need to perform recursive queries, cte are ideal choice

- **Subquery**
	- single value comparison in where clauses
```sql
# artists whose concert has greater than average revenue
select artist_name
from concerts
where concert_revenue > (select avg(concert_revenue) from concerts)
```

**column creation and aggregation**
- use subqueries to create new columns for real-time computations
```sql
select
	artist_name,
	genre,
	concert_revenue,
	(select avg(concert_revenue) from concerts) as avg_concert
	(select max(concert_revenue) from concerts) as avg_concert
from concerts;
```

**RANK**
- `RANK() over DATA`
- `RANK() over (partition by col_name order by col_name)`

**Aggregate Window**
- window are functions that operate by creating virtual windows within the dataset
- each window operate independently so we can do aggregate functions like sum, avg
- **Partition By**
	- ã…ã…ã… over ()
		- í•´ë‹¹ aggretation ìˆ˜í–‰
	- partition by
		- í•´ë‹¹ group ì— ëŒ€í•´
	- **ORDER BY**
		- sets up for incremental accumulation 
		- if not present, it fills in the same value for all same partition by column

- partition by a, b
	- 2ê°œë„ ê°€ëŠ¥

![[Pasted image 20250721173703.png]]
```sql
SELECT 
	user_id, 
	category, 
	product, 
	spend, 
	SUM(spend) OVER ( 
		PARTITION BY user_id ORDER BY transaction_date) AS cumulative_spend 
	FROM product_spend;
```
- **when "transaction_date" is identical to the next one, they both get 519.79**

**avg**
- as the window gets larger, it fetches the average of 2, 3, 4 rows

*EXCEPTION*
- LAST_VALUE() returns the last value of the entire partition, not expanding window


**RANK**
- assign ranks to rows based on partitioning and order expressions
- **rank**
	- ê³µë™ ìˆœìœ„ ì¡´ì¬, the next rank jumps from 4 -> 6
- **dense_rank**
	- ê³µë™ ìˆœìœ„ ì¡´ì¬, the rank does not jump
- **row_number**
	- assigns sequential ranks to each artist based on their concert revenue (unique)

```
select 
	col_1,
	col_2,
	row_number() over (order by concert_revenue) as row_num
	row_number() over (partition by country order by yof) as row_num
```

**time-series window functions**
- **lead()**
	- access data from rows that come after
- **lag()**
	- access data from rows before the current row
```
lead(col_name, offset) over (
	partition by partition_col
	order by order_col
)

or lag
```

**unbounded/bounded (value functions)**
- by default most of the functions have
	- `rows between unbounded preceding and current row`
	- hence, the last_value() will always be the value of the current row
- `rows between unbounded preceding and unbounded following`
	- applies on full partition
- `rows between current row and unbounded following`
	- reverse cumulative totals
- `rows between 1 and preceding and 1 following`
	- not selected
	- **selected**
	- **current_row**
	- **selected**
	- not selected

**unbounded/bounded (aggregate functions)**
- sum, avg, count, max, min
- `range between unbounded preceding and current row`


https://datalemur.com/sql-tutorial/sql-time-series-window-function-lead-lag










**with rollup**
- ì†Œê³„ë¥¼ ë§Œë“¤ì–´ ì¤Œ
- group by region, product with rollup;
	- east, A, 100
	- east, B, 150
	- east, Null, 250 < subtotal
	- west, A, 200
	- west, B, 250
	- west, null, 450 < subtotal
	- null, null, 700 < grand total

**grouping(column_name)**ã…
- returns 1 if the column is "rolled up"
- column_name ê¸°ì¤€ìœ¼ë¡œ ì§„í–‰

**offset**
`limit 2 offset 3;`
- limit ê°œìˆ˜ offset ê±´ë„ˆë›°ëŠ” ê°œìˆ˜
	- 1, 2 ê±´ë„ˆë›°ê³  3, 4, 5 return
- pagenation ì— ë§ì´ ì´ìš© ë¨

**Exists**
- subquery ì•ˆì— ê°’ì´ ì¡´ì¬í•˜ëŠ”ì§€, ì•ˆí•˜ëŠ”ì§€ì— ë”°ë¼ ë°–ì— ìˆëŠ” ì¿¼ë¦¬ì˜ ì‘ë™ ìœ ë¬´ë¥¼ íŒë‹¨




---

**DML (data manipulation language)**
- ë°ì´í„° ì¡°ì‘ ì–¸ì–´
- ì´ë¯¸ ì¡´ì¬í•˜ëŠ” table ì— ë°ì´í„° ì €ì¥, ìˆ˜ì •, ì‚­ì œ, ê²€ìƒ‰
- commit ê³¼ rollback ì´ ì ìš©ë˜ëŠ” ëª…ë ¹ì–´
- insert/update/delete


*mysqlì€ int ìë£Œí˜•ì˜ ì»¬ëŸ¼ì€ default ê°’ì´ 0*


`insert into emp01 (ename, deptno) values ('ì‹ ì§±êµ¬', 99), ('ì‹ ì§±ì•„', 99)`

`delete from emp01 where empno=0`

`update table_name set deptno=50 where empno=0;`

```
select @@autocommit;
set @@autocommit = 0; 
insert into ...
commit;

= 0 (false)
-- íŠ¸ëœì­ì…˜ ë‹¨ìœ„ë¡œ commitì„ ì‘ì„±í•  ë•Œê¹Œì§€ ì‹¤ì œ dbì—ëŠ” ë°˜ì˜ë˜ì§€ ì•ŠëŠ” ìƒíƒœ

-- select ì ˆì„ ì“°ë©´ ë°˜ì˜ì´ ëœê±¸ ë³¼ ìˆ˜ ìˆëŠ”ë°, temp memory ì—ë§Œ ë°˜ì˜ ë˜ê³ , ë‹¤ì‹œ ì‹œì‘í•˜ë©´ ë‚ ë¼ê°
```

```
start transaction;
insert into emp01 values (1, 'ì‹ ì§±êµ¬', 10);
SAVEPOINT sp1;
update emp01 set empno=3 where empno=1;
savepoint sp2;
delete from emp01 where empno=3;
savepoint sp3;

ROLLBACK to savepoint sp2;
```
- if rollbacked to sp1 and try sp2 again, its gone
- if you did sp3 first and sp1 then its okay
- unspecified rollback : start transaction ë°”ë¡œ ë‹¤ìŒìœ¼ë¡œ

*í•œêº¼ë²ˆì— ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë‹¨ìœ„ : transaction*

**truncate table emp01**
- ì •ë³´ë§Œ ë‹¤ ì—†ì• ê³  êµ¬ì¡°ë§Œ ë‚¨ê¹€

**drop table emp01**
- table ìì²´ê°€ ì‚¬ë¼ì§

**create table emp01 select empno, ename, hiredate, sal from emp;**


`alter table emp01 add column col_name INT;`

`update emp01 e01 join emp e on e.empno=e01.empno set e01.deptno2=e.deptno;`

`update emp01 set deptno = 30, job = 'MANAGER' where ename='SMITH';`

**UPSERT**
```
INSERT INTO people (name, age) VALUES ('ê¹€ì—°ì¬', 25)

ON DUPLICATE KEY UPDATE Â -- ON DUPLICATE KEYê°€ ì˜ë¯¸í•˜ëŠ” ê²ƒì€ ì‹¤ì œë¡œ UNIQUEê°€ ê±¸ë ¤ìˆëŠ” COLUMNì—ì„œì˜ DUPLICATEë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤

Â  name = 'ì¤‘ë³µê°’',

Â  age = age + 1;

SELECT * FROM people;
```

---
**INDEXING**
- DBì˜ ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•œ ìƒ‰ì¸ ê¸°ëŠ¥
- í´ëŸ¬ìŠ¤í„°í˜• ì¸ë±ìŠ¤
	- primary key, unique not null
	- ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ í‚¤ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ì¸ë±ìŠ¤
	- í•˜ë‚˜ì˜ í…Œì´ë¸”ì—ëŠ” í•˜ë‚˜ì˜ í´ëŸ¬ìŠ¤í„°í˜• ì¸ë±ìŠ¤ë§Œ ì¡´ì¬í•  ìˆ˜ ìˆìŒ
```
-- PKë¥¼ ì§€ì •í•˜ë©´ ì €ì ˆë¡œ í´ëŸ¬ìŠ¤í„°í˜• ì¸ë±ìŠ¤ê°€ ì§€ì •ë¨ ALTER TABLE students ADD PRIMARY KEY (id); -- ìœ„ ì½”ë“œì™€ ê°™ì€ ì˜ë¯¸ CREATE CLUSTERED INDEX idx_students_id ON students (id); -- ì œê±° DROP ì¸ë±ìŠ¤ëª… ON í…Œì´ë¸”ëª…; -- í™•ì¸ SHOW INDEX FROM students; SHOW TABLE STATUS LIKE 'students';
```

**Secondary Index**
- í…Œì´ë¸”ì—ì„œ ê¸°ë³¸ í‚¤ ì´ì™¸ì˜ ë‹¤ë¥¸ ì—´ì„ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±ë˜ëŠ” ì¸ë±ìŠ¤
- ì¤‘ë³µì„ í—ˆìš©í•˜ëŠ” / ì¤‘ë³µì„ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ì¸ë±ìŠ¤ 2ê°€ì§€ ë°©ë²•ì´ ì¡´ì¬
- í•œ í…Œì´ë¸”ë‹¹ ì—¬ëŸ¬ ë³´ì¡° ì¸ë±ìŠ¤ ìƒì„± ê°€ëŠ¥
```
CREATE INDEX idx_students_english ON students (english); 
CREATE UNIQUE INDEX idx_students_english ON students (english); 
ALTER TABLE students ADD INDEX idx_students_english (english); 
SELECT english FROM students; -- ê²°ê³¼ì˜ Execution Plan ì°½ì—ì„œ í™•ì¸í•´ë³´ê¸°
```

*ë„¤ì´ë° : ê¸°ëŠ¥ëª…_í…Œì´ë¸”ëª…_ì»¬ëŸ¼ëª…*

**When to use index**
- column that gets included in the where clause a lot
- column that gets used often
- remove unused index

**When to not use index**
- when index column is massive
	- requires more storage
- when there are multiple duplicate values (gender : male, female)
- index slows down insert, update, delete

```
create index index_name on table_name (col_1, col_2, col_3);
```

---
*self-paced*
**create database**
- `create new database test`

**create table**
- `create table emp01 as select(
	- a INT primary key,
	- b INT,
	- c INT`

**create index**
- `create idx_emp01_empno on emp01(empno)`

**multi-column index**
- `create index idx_usertbl_name_birthyear on usertbl(name, birthyear)`
- even when only one of them is called, index works 

**create unique index**
- enforces uniqueness even on columns that was not defined "unique" upon initial creation of 

**show index**
- `show index from tbl1`

**alter table**
- modify existing table structure
- `alter table my_table`
- `add constraint pk_name primary key (name)`
	- add primary key constraint
- `alter table mixed_table`
- `add constraint uk_mixed_table_name unique(name)`
	- add unique constraint
- `alter table usertable drop primary key`
- `alter table usertable drop index idx_usertbl_name_birthyear`
- `alter table table_name drop foreign key buytbl_ibfk_1`

*primary key = clustered index*
- it is automatically created when primary key is defined either during create table or alter table

**full text index**
- used for natural language text searching such as "%text%"
- `create fulltext index idx_content on articles(content)`

**show table status**
- provide table level metadata (row count, data length, index length, etc)
- `show table status like 'usertbl'`

**analyze table**
- analyze table usertbl;

**insert into**
- `insert into usertbl (col1, col2) values ('LSG', 'ì´ìŠ¹ê¸°', 1897)`

----
**integrity (ë¬´ê²°ì„±)**

**Create Table ... Constraints**
```
create table tbl_name (
	col1 datatype [constraints],
	...
	constraint constraint_name constraint_type(column)
)
```

**constraint types**
1. **primary key**
```
create table dept(
	deptno int not null
	constraint pk_dept primary key (deptno)
)
```
- auto-indexed & define clustered index

2. **unique**
- `empno int not null unique,`
- prevents duplicate values but allow null

3. **check**
- `age int check (age between 1 and 100)`
- `alter table emp05 add check (age > 0)`

4. **default**
- sets a default value if none is provided
- `age int default 1`

5. **foreign key**
- ensure referential integrity between parent and child tables
- child table's FK must match PK of parent table
```
alter table emp
add constraint fk_emp_dept
foreign key (deptno) references dept(deptno)
on delete no action on update no action;
```
- **on delete / on update**
	- **no action** : prevent deletion/update if references exist
	- **cascade** : automatically update/delete children
	- **set null** : sets fk field to null on parent deletion/update

**drop constraints**
- alter table emp drop primary key;
- alter table emp drop foreign key fk_emp_dept;
- alter table emp drop index uq_ename;


**information schema**
- stores metadata (not modifiable)
	- table constraints
	- columns
	- referential constraints
	- key column usage
```
SELECT * FROM information_schema.TABLE_CONSTRAINTS
WHERE table_name = 'emp';
```

---

ì¼ë°˜ ì§‘ê³„ í•¨ìˆ˜: Â  SUM, MAX, MIN, AVG, COUNT Â 
ê·¸ë£¹ ë‚´ í–‰ ìˆœì„œ í•¨ìˆ˜: FIRST_VALUE, LAST_VALUE, LAG, LEAD
ê·¸ë£¹ ë‚´ ë¹„ìœ¨ í•¨ìˆ˜: RATIO_TO_REPROT, PERCENT_RANK, CUME_DIST, NTILE ë“±


----

**Making Variables**
- set @var_name = var_value

```
SET @ë³€ìˆ˜ì´ë¦„ = ë³€ìˆ˜ì˜ ê°’; -- ë³€ìˆ˜ ì„ ì–¸ ë° ê°’ ëŒ€ì… 
SELECT @ë³€ìˆ˜ì´ë¦„; -- ë³€ìˆ˜ì˜ ê°’ ì¶œë ¥ 
SET @count = 5; 

SELECT code, name, continent, region, population 
FROM country 
WHERE population > 100000000 
ORDER BY @count ASC;
```
- ìœ„ì™€ ê°™ì´ ê·¸ëƒ¥ ì“°ë©´ variable ì´ ì œëŒ€ë¡œ ì‘ë™ í•˜ì§€ ì•ŠìŒ

```
SET @count = 5;
PREPARE mySQL FROM 'SELECT code, name, continent, region, population
  FROM world.country
 WHERE population > 100000000
 ORDER BY 1 ASC
 LIMIT ?';
EXECUTE mySQL USING @count;
```
- prepare - execute ë¬¸ì„ ê°™ì´ ì‚¬ìš© í•´ì•¼ í•¨

**Stored Procedure**
- ìì£¼ ì‚¬ìš©í•˜ëŠ” ì—¬ëŸ¬ê°œì˜ sql ë¬¸ë“¤ì„ í•œêº¼ë²ˆì— ë¬¶ì–´ì„œ ì¼ê´„ì ìœ¼ë¡œ ì²˜ë¦¬

```mysql
-- 82ë…„ë³´ë‹¤ ë¨¼ì € ì…ì‚¬í•œ ì‚¬ëŒì˜ ìˆ˜ë¥¼ ë¦¬í„´í•˜ëŠ” procedure
delimiter // -- ì‹œì‘
create procedure employees_hireyear(in target_year, out employee_count int) -- return variable & datatype
begin
	ì¿¼ë¦¬1;
	ì¿¼ë¦¬2;
	ì¿¼ë¦¬3;
	ì¿¼ë¦¬4;
end //
delimiter ; -- ë

call fisa.employees_hireyear(2, @hire_year);
```
- procedure/functions belong to a specific database.

```mysql
set @status_message = ''

create procedure employees_hireyear2(in target_year, out employee_count out status_message)
begin
	select count(*) into employee_count
	from fisa.emp
	where year(hiredate) < yarget_year;

	if employee_count > 10 then
		set status_message = 'ëª…ì˜ˆí‡´ì§ ê¸°ì”';
	else
		set status_message = 'OKAY';
	end if;
end //
```

**FUNCTION**
```mysql
create function employees_hireyear()
returns int -- ë¦¬í„´ë°›ì€ ìë£Œí˜•
deterministic -- ì…ë ¥ì— ë”°ë¼ ê°™ì€ ë¡œì§ì„ ì‚¬ìš©í•œ ê²°ê³¼ ì¶œë ¥
begin
	declare employee_count int;
	select count(*) into employee_count
	from fisa.emp where year(hiredate) < 1985;
	return employee_count;
```


*self-paced*

**stored procedure**
- saved script of sql commands that you can call and run with a single line
- `BEGIN,... , END`
- ì…ë ¥ê°’ (IN) & ì¶œë ¥ê°’ (OUT)
- delimiter ì„ í‘œì‹œí•´ì•¼ begin~end ë¸”ë¡ì„ ì¸ì‹ (//, ë“±)

```mysql
DELIMITER //
CREATE PROCEDURE procedure_name(IN param1 INT, OUT result INT)
BEGIN
    -- logic
END //
DELIMITER ;

CALL procedure_name(1985, @result);
SELECT @result;
```
- ìì£¼ ì‚¬ìš©í•˜ëŠ” ë¡œì§ ì¬ì‚¬ìš© ê°€ëŠ¥
- ë„¤íŠ¸ì›Œí¬ í†µì‹  íšŸìˆ˜ ê°ì†Œ -> ì„±ëŠ¥ í–¥ìƒ
- **DB ìƒíƒœ ë³€ê²½ ê°€ëŠ¥ (Insert, update, delete)**

**function**
- ë‹¨ì¼ ê°’ì„ ë°˜í™˜í•˜ëŠ” sql ì½”ë“œ ë¸”ë¡
- return ê°’ì´ ë°˜ë“œì‹œ ì¡´ì¬ í•´ì•¼ í•¨
- select, where, join ë“±ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
- **DB ìƒíƒœ ë³€ê²½ ë¶ˆê°€ëŠ¥**
- í•­ìƒ ê°™ì€ ì…ë ¥ -> ê°™ì€ ì¶œë ¥ì´ë©´ deterministic ì‚¬ìš©

```mysql
DELIMITER //
CREATE FUNCTION function_name(param INT)
RETURNS INT
DETERMINISTIC
BEGIN
    DECLARE result INT;
    SELECT COUNT(*) INTO result FROM emp WHERE year(hiredate) < param;
    RETURN result;
END //
DELIMITER ;

SELECT function_name(1985);
```
- must have exactly only one **return** value

**trigger**
- í…Œì´ë¸”ì—ì„œ ë³€í™”ê°€ ë°œìƒí•˜ë©´ ìë™ ì‹¤í–‰ë˜ëŠ” ì½”ë“œ
- before / after + insert / update / delete ì¡°í•©
- ë­”ê°€ ë°”ë€ŒëŠ” ìˆœê°„ (**delete, insert, update**) ìë™ ì‹¤í–‰
- new, old í‚¤ì›Œë“œë¥¼ ì‚¬ìš©í•´ì„œ ë³€ê²½ ì „/í›„ ë°ì´í„° ì ‘ê·¼

```mysql
delimiter //
create trigger trg_backup_order
after delete on orders
for each row -- ensure that the trigger runs once per affected row
begin
	insert into backup_order(order_id, customer_id, product_id, order_date, quantity)
	values (old.older_id, old.customer_id, old.product_id, old.order_date, old.quantity);

//
delimiter ;
```
- ***"FOR EACH ROW" ëŠ” CREATE TRIGGER ì— í•„ìˆ˜ í•­ëª©**
- does not work on **TRUNCATE**
- okay triggered by changes in the data (cannot just run it like a function)
- cannot use it on view

**ë³€ìˆ˜ ì„ ì–¸ & ì‚¬ìš©**
- declare variable_name int;
- set variable_name = 5;

**if inside procedure**
- if some_condition then
- -- something
- else
- -- something else
- end it

```
-- view triggers on a specific table
show triggers;
show triggers like 'table_name';

-- view trigger source code
select trigger_name, action_statement
from information_schema.triggers
where trigger_schema = 'your_database_name'

-- view stored procedures
show procedure status; --view all procedures
show procedure status where db = 'your_database_name'; -- filter by current database
show create procedure_name; -- view procedure definition

```






https://datalemur.com/sql-tutorial/sql-union-intercept-except
https://datalemur.com/questions/prime-warehouse-storage
----

**partition**
- MySQLì—ì„œ í…Œì´ë¸” íŒŒí‹°ì…˜ì€ í° í…Œì´ë¸”ì„ ë” ì‘ì€, ë” ê´€ë¦¬í•˜ê¸° ì‰¬ìš´ ë¶€ë¶„ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë°©ë²•ì…ë‹ˆë‹¤.
- ì´ë¥¼ í†µí•´ ì¿¼ë¦¬ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê³  ë°ì´í„° ê´€ë¦¬ë¥¼ ìš©ì´í•˜ê²Œ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. íŒŒí‹°ì…˜ì€ ë¬¼ë¦¬ì ìœ¼ë¡œëŠ” í•˜ë‚˜ì˜ í…Œì´ë¸”ì´ì§€ë§Œ, ë…¼ë¦¬ì ìœ¼ë¡œëŠ” ì—¬ëŸ¬ ê°œì˜ ì‘ì€ í…Œì´ë¸”ì²˜ëŸ¼ ë™ì‘í•©ë‹ˆë‹¤.

- **partition ìœ í˜•**
	- **range**
		- íŠ¹ì • ë²”ìœ„ì˜ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„í• 
		- ë‚ ì§œ ë²”ìœ„, ìˆ«ì ë²”ìœ„ ë“±
	- **list**
		- íŠ¹ì • ê°’ ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë¶„í• 
		- íŠ¹ì • ì§€ì—­ ì½”ë“œ, ìƒíƒœ ì½”ë“œ ë“±
	- **hash**
		- í•´ì‹œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ê· ë“±í•˜ê²Œ ë¶„í• 
		- íŠ¹ì • ì—´ì˜ í•´ì‹œ ê°’ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• 
	- **key**
		- mysql ë‚´ë¶€ í•´ì‹œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í• 
		- í•´ì‹œ í•¨ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì„ íƒ

- ***When using "partition by", the partition key must be part of every unique key****
	- unique key
	- primary key


**ì •ê·œí™”**
- ì¤‘ë³µ ë°ì´í„°ë¥¼ ì¤„ì´ê³ , ë°ì´í„° ë¬´ê²°ì„±ì„ ë†’ì´ê¸° ìœ„í•œ ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ì›ì¹™

| ì •ê·œí˜• | ëª©ì                                                                                            | ì¡°ì¹˜ ë‚´ìš©                | ì¥ì                           |
| --- | -------------------------------------------------------------------------------------------- | -------------------- | --------------------------- |
| 1NF | ì›ìê°’ ìœ ì§€(ì¹¸ë§ˆë‹¤ í•˜ë‚˜ë§Œ!)                                                                             | ë°˜ë³µê°’ ë¶„ë¦¬ (ì œì‘ì‚¬ ë“±)       | ì²˜ë¦¬ ìš©ì´, ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ            |
| 2NF | ë¶€ë¶„ ì¢…ì† ì œê±°(ì¤‘ë³µë˜ëŠ” ê±¸ ë‹¤ë¥¸ í‘œë¡œ!)                                                                      | ê¸°ê´€ ì •ë³´(ìˆ˜ì…ì‚¬, ë°°ê¸‰ì‚¬ ë“±) ë¶„ë¦¬ | ì¤‘ë³µ ì œê±°(ì €ì¥ê³µê°„ í™•ë³´), ë¬´ê²°ì„± ìœ ì§€,     |
| 3NF | ì´í–‰ì  ì¢…ì† ì œê±°(ì •ë³´ëŠ” í•œ ê³³ì—ë§Œ!)                                                                        | ì˜ë¯¸ ë‹¨ìœ„ ë¶„ë¦¬             | í…Œì´ë¸” ì˜ë¯¸ ëª…í™•í™”                  |
| 4NF | ë‹¤ì¹˜ ì¢…ì† ì œê±°(ì—¬ëŸ¬ ê°œì˜ ë…ë¦½ì ì¸ ì •ë³´ëŠ” ë”°ë¡œ!)                                                                 | N:M ê´€ê³„ í…Œì´ë¸” ë¶„ë¦¬        | ê´€ê³„ ëª…í™•, ì¤‘ë³µ ìµœì†Œí™”, ê´€ë ¨ì´ ì—†ëŠ” ì¡°í•© ë¶„ë¦¬ |
| 5NF | ì¡°ì¸ ì¢…ì† ì œê±°(**ë³µí•©í‚¤ ì‚¬ìš©,** ë•Œë¡œëŠ” ì¤‘ë³µì„ ê°ìˆ˜í•˜ë”ë¼ë„ ì„œë¡œ ë‹¤ë¥¸ í•„ë“œì˜ ë°ì´í„°ê°€ ì •í™•íˆ ê°™ì´ ìˆì–´ì•¼ ì˜ë¯¸ê°€ ìˆëŠ” ê²½ìš° **ì •í™•í•œ ê´€ê³„**ë¥¼ ë‹¤ì‹œ ì˜ ì—°ê²°) | ì¡°ì¸ ë³µì› ë³´ì¥             | ë°ì´í„° ì •í™•ì„±, êµ¬ì¡° í™•ì¥ ìš©ì´           |

1nf
- ensure that data contains only atomic values
- atomic values
	- each entry in a column is indivisible

2nf
- eliminate partial dependencies
	- assure that non-key attributes depend only on the primary key
- **primary key ê°€ í•œê°œ ì´ìƒì˜ ì—´ë¡œ ì´ë£¨ì–´ì§„ í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€**
	- 2ê°œ ì´ìƒì˜ columnìœ¼ë¡œ uniqueness ë¥¼ ë³´ì¥í•´ì•¼ í•  ì‹œ
- **is any non-prime attribute functionally dependent on the whole key**
	- functionally dependent : Aì—´ì˜ ê°’ì´ Bì—´ì˜ ê°’ì„ 1:1ë¡œ ìœ ì¶”í•  ìˆ˜ ìˆì„ ì‹œ
- redundancy patterns
	- í•œ column ì— ì¤‘ë³µë˜ëŠ” ê°’ì´ ì¡´ì¬
	- non-prime attribute ë“¤ì´ compose key ì˜ ì¼ë¶€ (í•œ column) ì— ëŒ€í•´ì„œë§Œ dependent í•  ì‹œ

3nf
- remove transitive dependency
	- ensure non-key attribute
1. **define non-prime attributes**
2. **for each non-prime attribute**
	1. is it fully dependent on the entire key?
	2. is it indirectly dependent on the key (is it dependent on another column, and that column is dependent on the pk) 
		1. if yes -> transitive dependency
	3. does non-prime attribute determine another non-prime attribute


bcnf
- every determinant is a candidate key
	- determinant : attribute that determines another attribute


4nf
- there is non-trivial multivalued dependencies other than a candidate key


5nf
- every join dependency in the relation is implied by the candidate keys
1. are you storing 3 or more independent relationships in one table?
2. can the table be decomposed into 3+ tables and joined back losslessly
3. is there a lossy join when decomposing into 3+ relations?
	1. lossy join : when you join the decomposed relations, 
		1. you get extra rows
		2. you lose information (some rows disappear)
4. are there join dependencies not implied by candidate keys?
	1. if so did you decompose into minimal projections to fix it?

***Determine logical groups and their relationship first, then perform normalization within each group***

***always model the data objectively based on the real-world entities and relationships, then layer business-centric views or query paths on top of that***


**pivoting**
- rotating table by converting unique values from a single column into multiple columns

```
SELECT
  superhero_alias,
  MAX(CASE WHEN platform = 'Instagram' THEN engagement_rate END) AS instagram_engagement_rate,
  MAX(CASE WHEN platform = 'Twitter' THEN engagement_rate END) AS twitter_engagement_rate,
  MAX(CASE WHEN platform = 'TikTok' THEN engagement_rate END) AS tiktok_engagement_rate,
  MAX(CASE WHEN platform = 'YouTube' THEN engagement_rate END) AS youtube_engagement_rate
FROM marvel_avengers
WHERE superhero_alias IN ('Iron Man', 'Captain America', 'Black Widow', 'Thor')
GROUP BY superhero_alias
ORDER BY superhero_alias;
```

**unpivoting**
- transform columns into row values
- equivalant to `melt`

```
SELECT
  superhero_alias,
  platform,
  CASE platform
    WHEN 'Instagram' THEN engagement_rate
    WHEN 'Twitter' THEN engagement_rate
    WHEN 'YouTube' THEN engagement_rate
    WHEN 'TikTok' THEN engagement_rate
  END AS engagement_rate
FROM marvel_avengers
WHERE superhero_alias IN ('Iron Man', 'Captain America', 'Black Widow', 'Thor')
ORDER BY superhero_alias;
```

---
**sql regex**
- \d - digit
- \w - any letter
- \s - " "
- \t - tab

**pattern matching (only available in postgresql)**
- `~` - case insensitive
- `!~` - not & case insensitive
	- used like `Like`
- `SELECT * FROM users WHERE name !~* 'admin';`

---
**Nulls behavior**
- COUNT(col)
	- if column is (1, NULL), then it returns 1 (ignores NULL when count)
- COUNT (`*`)
	- counts rows, return 2
- NOT IN()
	- fails if the subquery returns any NULL
- NOT EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id)
	- NULL-safe
	- inside exists/not exists, the actual columns don't matter
	- the engine only checks if a row exists
		- `SELECT 1`, `SELECT *`, `SELECT 42`â€”all equivalent for existence checks.

**postgresql equivalance of last_value that is not null (ignore null)**
```sql
COALESCE(
  val,
  MAX(CASE WHEN val IS NOT NULL THEN val END)
    OVER (PARTITION BY acct ORDER BY ts
          ROWS BETWEEN UNBOUNDED PRECEDING AND 1 PRECEDING)
)
```

**anti-join**
- a query that returns rows in A that have no match in B

**boolean expression on ON**
- it filters before/during the join
- where filters after the join


**ALL()**
- `WHERE val >= ALL(SELECT val FROM t)`
- determine bool based on OP


60 min
24 mcq
4 sql
1 diagram (drag and drop)





# ğŸ“ SQL Window & Pivot Cheatsheet (Data Engineer Preset)

## 1. Ranking & Row Number

`-- Row number within partition 
```sql
SELECT      customer_id,     order_date,     ROW_NUMBER() OVER (PARTITION BY customer_id ORDER BY order_date) AS rn FROM orders;  
```

```sql
-- Ranking with ties 
SELECT      product_id,     RANK() OVER (PARTITION BY category ORDER BY revenue DESC) AS rnk FROM sales;  

-- Dense ranking (no gaps) 
SELECT      product_id,     DENSE_RANK() OVER (ORDER BY revenue DESC) AS drnk FROM sales;
```
---

## 2. First / Last Value

`-- First and last purchase date per customer SELECT      customer_id,     FIRST_VALUE(order_date) OVER (PARTITION BY customer_id ORDER BY order_date ASC) AS first_order,     LAST_VALUE(order_date) OVER (PARTITION BY customer_id ORDER BY order_date ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS last_order FROM orders;`

âš ï¸ Remember: `LAST_VALUE` needs a proper frame (`ROWS BETWEEN ...`) or it defaults incorrectly.

---

## 3. Moving / Sliding Windows

`-- 7-day rolling sum of revenue SELECT     order_date,     SUM(revenue) OVER (         ORDER BY order_date         ROWS BETWEEN 6 PRECEDING AND CURRENT ROW     ) AS rolling_7d_sum FROM sales;  -- Previous and next row comparison SELECT     order_id,     revenue,     LAG(revenue, 1) OVER (ORDER BY order_date) AS prev_revenue,     LEAD(revenue, 1) OVER (ORDER BY order_date) AS next_revenue FROM sales;`

---

## 4. Running Totals & Cumulative Dist

`-- Running total of sales per customer SELECT      customer_id,     order_date,     SUM(amount) OVER (PARTITION BY customer_id ORDER BY order_date ROWS UNBOUNDED PRECEDING) AS running_total FROM orders;  -- Cumulative percentage SELECT      product_id,     revenue,     SUM(revenue) OVER (ORDER BY revenue DESC) * 1.0 /     SUM(revenue) OVER () AS cumulative_pct FROM sales;`

---

## 5. Percentiles & N-Tile

`-- Quartiles SELECT      customer_id,     NTILE(4) OVER (ORDER BY total_spent DESC) AS quartile FROM customer_spending;  -- Median revenue (approx using percentile) SELECT DISTINCT     PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY revenue)      OVER () AS median_revenue FROM sales;`

---

## 6. Pivot / Unpivot

`-- Pivot: sales by region into columns SELECT * FROM (     SELECT region, product, revenue     FROM sales ) src PIVOT (     SUM(revenue)     FOR region IN ([APAC], [EMEA], [AMER]) ) p;  -- Unpivot: columns back into rows SELECT product, region, revenue FROM sales_pivoted UNPIVOT (     revenue FOR region IN ([APAC], [EMEA], [AMER]) ) u;`

ğŸ’¡ Works in SQL Server/Oracle. For Postgres/ANSI: use `FILTER` or `CASE WHEN` aggregations.

---

## 7. Conditional Aggregates (Poor Manâ€™s Pivot)

`-- Pivot-like aggregation (portable SQL) SELECT     product,     SUM(CASE WHEN region = 'APAC' THEN revenue END) AS apac_rev,     SUM(CASE WHEN region = 'EMEA' THEN revenue END) AS emea_rev,     SUM(CASE WHEN region = 'AMER' THEN revenue END) AS amer_rev FROM sales GROUP BY product;`

---

## 8. Gap & Island Detection (Sessions)

`-- Identify continuous sessions (gaps > 1 day = new session) SELECT      user_id,     login_date,     SUM(CASE WHEN DATEDIFF(day, LAG(login_date) OVER (PARTITION BY user_id ORDER BY login_date), login_date) > 1 THEN 1 ELSE 0 END)         OVER (PARTITION BY user_id ORDER BY login_date) AS session_id FROM logins;`

---

## 9. Top-N Per Group

`-- Get top 3 products by revenue in each category SELECT * FROM (     SELECT          category,         product,         revenue,         ROW_NUMBER() OVER (PARTITION BY category ORDER BY revenue DESC) AS rn     FROM sales ) t WHERE rn <= 3;`

---

## 10. Window Function + Joins (Common Data Eng Use)

`-- Detect anomalies: revenue deviation from group avg SELECT     s.*,     revenue - AVG(revenue) OVER (PARTITION BY category) AS deviation FROM sales s;`













----

#### Null Cheat Sheet

# 1) What NULL _is_ (and is not)
- **Meaning:** â€œunknown / missing / not applicable.â€ It is **not** a value.
- **Not the same as:** `0`, empty string, `FALSE`, or a blank. (One major vendor historically treats empty string as NULLâ€”donâ€™t rely on that across systems.)
    

---

# 2) Three-valued logic (3VL)

- SQL uses **TRUE / FALSE / UNKNOWN**    
- Any comparison with NULL (e.g., `=`, `<>`, `<`, `>=`) yields **UNKNOWN**.
- **WHERE keeps only TRUE.** Rows that evaluate to FALSE **or UNKNOWN** are filtered out.
    
- Boolean rules you must know:
    - `TRUE AND UNKNOWN` â†’ UNKNOWN
    - `FALSE AND UNKNOWN` â†’ FALSE
    - `TRUE OR UNKNOWN` â†’ TRUE
    - `FALSE OR UNKNOWN` â†’ UNKNOWN
    - `NOT UNKNOWN` â†’ UNKNOWN

> Exam trap: a predicate that becomes UNKNOWN **wonâ€™t pass the WHERE filter**.

---

# 3) Testing for NULL

- Use **â€œis nullnessâ€ predicates**: **IS NULL** / **IS NOT NULL**.
- Equality/inequality operators (`=`, `<>`) **do not** work with NULL.
- Some DBs support **null-safe equality** (treats `NULL` = `NULL` as TRUE) or **â€œis distinct fromâ€** style operations. These are _not_ universalâ€”know they exist conceptually.

---

# 4) Comparisons, arithmetic, concatenation
- **Comparisons:** any `value OP NULL` â†’ **UNKNOWN**.
- **Arithmetic:** `NULL` in an expression â†’ **NULL** result (e.g., `price * NULL` â†’ NULL).
- **String concat:** if any side is NULL â†’ result is usually **NULL** (donâ€™t assume empty string).
---

# 5) Aggregates & GROUP BY
- **COUNT(`*`)** counts **rows** (includes NULL rows).
- **COUNT(col)** counts **non-NULL values** only.
- **SUM/AVG/MIN/MAX** **ignore NULL inputs** (they aggregate only existing values).
- **AVG** equals `SUM(non-NULL)/COUNT(non-NULL)`.
- **GROUP BY**: all rows with NULL in a grouping column form **one group** (treat NULLs as one bucket).
- **DISTINCT**: multiple NULLs collapse to a **single distinct** NULL.

> Exam traps:  
> â€¢ â€œWhy do my counts differ?â€ â†’ `COUNT(col)` vs `COUNT(*)`.  
> â€¢ â€œAVG with NULLsâ€ â†’ denominator is non-NULL count.

---

# 6) HAVING vs WHERE with NULL

- **WHERE** filters **before** aggregation; **HAVING** filters **after** aggregation.
- A `WHERE col = something` drops NULL rows (predicate is UNKNOWN).
- To filter on aggregate results (which already skipped NULLs), use **HAVING**.

---

# 7) Joins & NULL
- Join conditions that compare to NULL **never match** (comparison becomes UNKNOWN).
- **INNER JOIN:** rows with NULLs in the join keys will not match.
- **LEFT JOIN:** keeps all left rows; unmatched right side appears as NULLs.
- **Filtering after LEFT JOIN**:
    - Put right-table conditions in **WHERE** â†’ might **turn it into an inner-like** (unmatched rows dropped).
    - Put right-table conditions in the **ON** clause â†’ **preserve** unmatched left rows; unmatched rights stay NULL.

> Diagram/MCQ trap: â€œWhy did my LEFT JOIN drop rows?â€ â†’ because a right-side filter was placed in WHERE instead of ON.

---

# 8) Anti-joins (A without matching B)

- Safe patterns conceptually:
    - **LEFT-join then keep rows where right is NULL.**
    - **NOT EXISTS** subquery.

- **NOT IN** subquery is dangerous if the subquery can return **NULLs**; the result becomes UNKNOWN and often matches **nothing**.

```sql
SELECT c.id, c.name
FROM customers c
WHERE c.id NOT IN (SELECT cust_id FROM orders);
Subquery result: {1, 2, NULL}

Now check each customer:

Alice (1): 1 NOT IN {1,2,NULL} â†’ UNKNOWN (because NULL in set) â†’ excluded.

Bob (2): same â†’ UNKNOWN â†’ excluded.

Carol (3): 3 NOT IN {1,2,NULL} â†’ UNKNOWN â†’ excluded.

Dave (4): 4 NOT IN {1,2,NULL} â†’ UNKNOWN â†’ excluded.
```

> MCQ classic: â€œWhich anti-join is NULL-safe?â€ â†’ NOT EXISTS or LEFTâ€¦IS NULL; avoid NOT IN if the subquery column may contain NULL.

---

# 9) Subqueries & NULL

- **IN** with a subquery that returns NULLs still works for positives, but:
    
- **NOT IN** with **any** NULL in subquery â†’ overall predicate becomes UNKNOWN â†’ typically yields **no rows**.
    
- **EXISTS/NOT EXISTS** arenâ€™t affected by subquery column values (only row existence).
    

---

# 10) ORDER BY with NULLs

- Default placement (**NULLS FIRST/LAST**) **varies by vendor** and by sort direction.
    
- Best practice: **explicitly choose** first/last if you care. (Conceptual noteâ€”syntax varies.)
    

---

# 11) Window functions & NULL

- **Windowed aggregates** follow the same rule as normal aggregates: **they ignore NULL inputs**.
    
- **Window frames**:
    
    - **ROWS**: row-count windows (e.g., last 3 rows).
        
    - **RANGE**: value-based windows (e.g., last 7 days by timestamp/order key).
        
- â€œLast non-NULLâ€ carry-forward generally requires a special technique; some engines offer â€œignore NULLsâ€ options, others donâ€™t. Concept: compute a running â€œlast seen non-NULLâ€ and coalesce.

- **Positional window functions (first_value, last_value, ...)**
	- do not ignore NULLs by default

> MCQ trap: â€œ7-day sliding window with multiple rows/dayâ€ â†’ use **value-based** (RANGE by time), not row-based (ROWS).

---

# 12) CASE expressions with NULL

- Comparisons like `CASE WHEN salary > 0` with `salary` NULL â†’ condition is UNKNOWN â†’ falls to **ELSE**.
    
- To treat NULL as 0 (or text), **wrap with a NULL-handling function** (see Â§14).

---

# 13) Constraints & NULL

- **PRIMARY KEY** implies **NOT NULL** (no NULLs allowed).
    
- **UNIQUE** constraints typically allow **multiple NULLs** because NULL â‰  NULL (not equal, unknown).
    
- **FOREIGN KEY** columns may be **NULL** â†’ means â€œno referenceâ€ (not a violation).
    
- **CHECK** constraints can forbid NULLs explicitly.
    

> Exam trap: â€œCan unique columns have multiple NULLs?â€ â†’ Generally **yes**.

---

# 14) NULL-handling functions (portable concepts)

- **COALESCE(a, b, c, â€¦)**: returns the first **non-NULL** argument.
    
    - Use to **default** NULLs (e.g., to 0 or â€˜N/Aâ€™) or to align datatypes.
        
- **NULLIF(a, b)**: returns **NULL** if `a` equals `b`, else returns `a`.
    
    - Use to **avoid divide-by-zero** (e.g., divide by `NULLIF(den, 0)` â†’ becomes NULL instead of error).
        
- Vendor-specific aliases (concept only): most platforms have a short form (e.g., â€œif-nullâ€) but names differâ€”**COALESCE/NULLIF** are the portable ideas.
    
- **IS [NOT] NULL**: only reliable way to test nullness across engines.
    

---

# 15) DISTINCT, UNION, INTERSECT, EXCEPT with NULL

- **DISTINCT** treats all NULLs as the **same** for deduplication.
    
- **UNION** (and UNION ALL vs UNION): with **UNION** duplicates are removedâ€”**NULL rows dedupe** as well.
    
- **INTERSECT/EXCEPT**: comparisons use SQL semantics; NULLs compare in a way consistent with set logic (e.g., a NULL row matches another identical NULL row structurally).
    

---

# 16) Defaults vs NULL on insert

- **Omitting a column** can trigger its **DEFAULT**.
    
- **Inserting NULL explicitly** typically **bypasses** the DEFAULT and stores NULL (unless constrained).
    
- If column is **NOT NULL**, inserting NULL fails.
    

---

# 17) Indexes & NULL (high-level)

- Whether NULLs are indexed or how they behave in indexes can **vary**.  
    Treat **IS NULL** and **IS NOT NULL** predicates as potentially indexable, but **do not rely** on uniform behavior across engines.
    

---

# 18) Data-quality patterns with NULL

- Decide per column: does NULL mean â€œunknown,â€ or should you store a **sentinel** (e.g., 0 or empty string)? Mixing both leads to pain.
    
- For facts:
    
    - Use **foreign-key checks** to prevent orphaned references (or quarantine rows).
        
    - Use **COALESCE** for numeric rollups when you truly want missing = 0.
        
- For dimensions:
    
    - Be consistent: NULL vs â€œUnknownâ€ member (a special key) for referential completeness.
        

---

# 19) Classic NULL pitfalls (youâ€™ll see these in tests)

1. **`NOT IN` with NULLs in the subquery** â†’ returns **no rows**. Use **NOT EXISTS** or clean the NULLs.
    
2. **LEFT JOIN + WHERE filter on right** â†’ drops unmatched rows (behaves like inner). Put the filter in **ON** to preserve left rows.
    
3. **`COUNT(col)` vs `COUNT(*)`** â†’ they differ when col has NULLs.
    
4. **AVG with NULLs** â†’ denominator is count of **non-NULL** rows.
    
5. **Comparisons to NULL** â†’ always UNKNOWN; use **IS NULL**.
    
6. **Window: ROWS vs RANGE** â†’ only RANGE can express value-based windows like â€œlast 7 days.â€
    
7. **UNIQUE with NULLs** â†’ generally allows multiple NULLs.
    

---

# 20) Quick mental checklist for any SQL with NULLs

- Am I **testing** for NULL properly (IS NULL) instead of `= NULL`?
    
- Will this **join** lose rows because join keys can be NULL?
    
- If Iâ€™m doing **A minus B**, is my anti-join **NULL-safe** (NOT EXISTS / LEFTâ€¦IS NULL)?
    
- Do I want **row-based** or **value-based** window frames?
    
- Do my **aggregates** do what I expect with NULLs (COUNT(col) vs COUNT(*))?
    
- Should I **default** NULLs (COALESCE) for the business requirement?
    
- Do I need a **BI-safe** â€œUnknown memberâ€ instead of NULL for a foreign key?


---

